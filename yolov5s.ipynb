{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "E5eYtU1dkoRK"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/sample_data', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5s"
      ],
      "metadata": {
        "id": "w7i7tLvPlSuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "zDE3azwBlaEO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages"
      ],
      "metadata": {
        "id": "qe26woeolfw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def install_requirements():\n",
        "    packages = [\n",
        "        \"ultralytics\",\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"tensorflow\",\n",
        "        \"onnx\",\n",
        "        \"onnx2tf\",\n",
        "        \"onnxsim\",\n",
        "        \"opencv-python\",\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    print(\"All required packages installed successfully!\")"
      ],
      "metadata": {
        "id": "lvsMShEImedz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for existing dataset or download COCO128"
      ],
      "metadata": {
        "id": "r2-oh6GLnFQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset():\n",
        "    # List of common dataset locations to check\n",
        "    potential_datasets = [\n",
        "        \"/content/dataset\",\n",
        "        \"/content/custom_dataset\",\n",
        "        \"/content/yolo_dataset\",\n",
        "        \"/content/coco128\"\n",
        "    ]\n",
        "\n",
        "    # Check for existing datasets\n",
        "    for dataset_path in potential_datasets:\n",
        "        if os.path.exists(dataset_path):\n",
        "            # Look for YOLO dataset structure (images and labels folders)\n",
        "            images_dir = os.path.join(dataset_path, 'images')\n",
        "            labels_dir = os.path.join(dataset_path, 'labels')\n",
        "\n",
        "            # Also check for common YOLO yaml files\n",
        "            yaml_files = [f for f in os.listdir(dataset_path) if f.endswith('.yaml') or f.endswith('.yml')]\n",
        "\n",
        "            if os.path.exists(images_dir) and os.path.exists(labels_dir):\n",
        "                # Check if folders have content\n",
        "                has_images = len([f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]) > 0\n",
        "                has_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith('.txt')]) > 0\n",
        "\n",
        "                if has_images and has_labels:\n",
        "                    print(f\"Existing dataset found at: {dataset_path}\")\n",
        "\n",
        "                    # Try to find or create a yaml file\n",
        "                    yaml_path = None\n",
        "                    if yaml_files:\n",
        "                        yaml_path = os.path.join(dataset_path, yaml_files[0])\n",
        "                        print(f\"Using existing yaml file: {yaml_files[0]}\")\n",
        "                    else:\n",
        "                        # Create a basic yaml file\n",
        "                        yaml_path = create_basic_yaml(dataset_path)\n",
        "\n",
        "                    return dataset_path, yaml_path\n",
        "\n",
        "    # No existing dataset found, download COCO128\n",
        "    print(\"No existing dataset found. Downloading COCO128...\")\n",
        "    coco128_path = download_coco128()\n",
        "    yaml_path = os.path.join(coco128_path, 'coco128.yaml')\n",
        "\n",
        "    return coco128_path, yaml_path"
      ],
      "metadata": {
        "id": "lqJWe4dlnKgr"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_basic_yaml(dataset_path):\n",
        "    yaml_content = f\"\"\"# Dataset configuration\n",
        "path: {dataset_path}\n",
        "train: images\n",
        "val: images\n",
        "\n",
        "# Classes (will be auto-detected from labels)\n",
        "nc: 80  # number of classes (placeholder)\n",
        "names: ['class0', 'class1', 'class2']  # class names (placeholder)\n",
        "\"\"\"\n",
        "    yaml_path = os.path.join(dataset_path, 'dataset.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Created basic yaml configuration: {yaml_path}\")\n",
        "    return yaml_path"
      ],
      "metadata": {
        "id": "A3JT_zjhnc-Y"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_coco128():\n",
        "    dataset_url = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\"\n",
        "    dataset_path = \"/content/coco128.zip\"\n",
        "    extract_path = \"/content/\"\n",
        "\n",
        "    print(\"Downloading COCO128 dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # Remove zip file to save space\n",
        "    os.remove(dataset_path)\n",
        "\n",
        "    # Verify the yaml file exists and fix path if needed\n",
        "    coco128_dir = \"/content/coco128\"\n",
        "    yaml_file = os.path.join(coco128_dir, \"coco128.yaml\")\n",
        "\n",
        "    if not os.path.exists(yaml_file):\n",
        "        print(\"coco128.yaml not found, creating configuration...\")\n",
        "        create_coco128_yaml(coco128_dir)\n",
        "\n",
        "    print(\"COCO128 dataset downloaded and extracted successfully!\")\n",
        "    return coco128_dir"
      ],
      "metadata": {
        "id": "0t3NE8EBnlQ5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_coco128_yaml(dataset_path):\n",
        "    yaml_content = f\"\"\"# COCO128 dataset configuration\n",
        "path: {dataset_path}\n",
        "train: images/train2017\n",
        "val: images/train2017\n",
        "\n",
        "# Classes\n",
        "nc: 80\n",
        "names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "        'hair drier', 'toothbrush']\n",
        "\"\"\"\n",
        "\n",
        "    yaml_path = os.path.join(dataset_path, 'coco128.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Created coco128.yaml at: {yaml_path}\")"
      ],
      "metadata": {
        "id": "bXM1SyGprRpn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolov5s(yaml_path, epochs=100, imgsz=640):\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    print(\"Initializing YOLOv5s model...\")\n",
        "    model = YOLO('yolov5s.pt')  # Load pretrained YOLOv5s model\n",
        "\n",
        "    print(f\"Starting training for {epochs} epochs...\")\n",
        "    print(f\"Using dataset configuration: {yaml_path}\")\n",
        "\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        batch=16,\n",
        "        device=0 if os.system('nvidia-smi') == 0 else 'cpu',  # Use GPU if available\n",
        "        project='/content/yolov5_training',\n",
        "        name='yolov5s_experiment',\n",
        "        save=True,\n",
        "        cache=True,\n",
        "        verbose=True,\n",
        "        patience=10,  # Early stopping patience\n",
        "        save_period=10  # Save checkpoint every 10 epochs\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, results"
      ],
      "metadata": {
        "id": "GDhXeI_nnoDT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_model_formats(model, export_dir=\"/content/exported_models\"):\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Exporting YOLOv5s model to different formats...\")\n",
        "\n",
        "    # Export to ONNX (intermediate format for TensorFlow conversion)\n",
        "    print(\"Exporting to ONNX...\")\n",
        "    onnx_path = model.export(format='onnx', dynamic=False, simplify=True)\n",
        "    print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "    # Export to TorchScript\n",
        "    print(\"Exporting to TorchScript...\")\n",
        "    try:\n",
        "        torchscript_path = model.export(format='torchscript')\n",
        "        print(f\"TorchScript model exported to: {torchscript_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"TorchScript export failed: {e}\")\n",
        "        torchscript_path = None\n",
        "\n",
        "    # Export to TensorFlow SavedModel format\n",
        "    print(\"Exporting to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        tf_path = model.export(format='saved_model')\n",
        "        print(f\"TensorFlow SavedModel exported to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Direct TensorFlow export failed: {e}\")\n",
        "        tf_path = None\n",
        "\n",
        "    return onnx_path, tf_path, torchscript_path"
      ],
      "metadata": {
        "id": "_er9x-WMnqTL"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tflite(onnx_path, output_dir=\"/content/tflite_models\"):\n",
        "    import tensorflow as tf\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # First convert ONNX to TensorFlow SavedModel using onnx2tf\n",
        "        print(\"Converting ONNX to TensorFlow SavedModel...\")\n",
        "        saved_model_dir = f\"{output_dir}/saved_model\"\n",
        "\n",
        "        # Use onnx2tf for conversion\n",
        "        cmd = f\"onnx2tf -i {onnx_path} -o {saved_model_dir} --non_verbose\"\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "        # Convert TensorFlow SavedModel to TensorFlow Lite\n",
        "        print(\"Converting TensorFlow SavedModel to TensorFlow Lite...\")\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "\n",
        "        # Optimization settings for mobile deployment\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.target_spec.supported_types = [tf.float16]  # Use FP16 for smaller size\n",
        "\n",
        "        # Additional optimization for YOLOv5s\n",
        "        converter.allow_custom_ops = True\n",
        "        converter.experimental_new_converter = True\n",
        "\n",
        "        # Convert the model\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save the TensorFlow Lite model\n",
        "        tflite_path = f\"{output_dir}/yolov5s_coco128.tflite\"\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"TensorFlow Lite model saved to: {tflite_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)  # Size in MB\n",
        "        print(f\"TensorFlow Lite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return tflite_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite conversion failed: {e}\")\n",
        "        print(\"Trying quantized conversion method...\")\n",
        "\n",
        "        # Try quantized conversion for better compatibility\n",
        "        try:\n",
        "            return convert_to_tflite_quantized(onnx_path, output_dir)\n",
        "        except Exception as e2:\n",
        "            print(f\"Quantized conversion also failed: {e2}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "Gsyv4-F5ntlw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tflite_quantized(onnx_path, output_dir):\n",
        "    import tensorflow as tf\n",
        "\n",
        "    print(\"Attempting quantized TensorFlow Lite conversion...\")\n",
        "\n",
        "    saved_model_dir = f\"{output_dir}/saved_model\"\n",
        "\n",
        "    # Convert ONNX to SavedModel first\n",
        "    cmd = f\"onnx2tf -i {onnx_path} -o {saved_model_dir} --non_verbose\"\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "    # Convert with quantization\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "\n",
        "    # Enable quantization\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = generate_representative_dataset\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.uint8\n",
        "    converter.inference_output_type = tf.uint8\n",
        "\n",
        "    # Convert\n",
        "    quantized_tflite_model = converter.convert()\n",
        "\n",
        "    # Save quantized model\n",
        "    quantized_tflite_path = f\"{output_dir}/yolov5s_quantized.tflite\"\n",
        "    with open(quantized_tflite_path, 'wb') as f:\n",
        "        f.write(quantized_tflite_model)\n",
        "\n",
        "    model_size = os.path.getsize(quantized_tflite_path) / (1024 * 1024)\n",
        "    print(f\"Quantized TensorFlow Lite model saved to: {quantized_tflite_path}\")\n",
        "    print(f\"Quantized model size: {model_size:.2f} MB\")\n",
        "\n",
        "    return quantized_tflite_path"
      ],
      "metadata": {
        "id": "20dZb8-pTVrR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_representative_dataset():\n",
        "    import numpy as np\n",
        "\n",
        "    # Generate representative dataset for quantization\n",
        "    for _ in range(100):\n",
        "        # Random input matching YOLOv5s input shape [1, 3, 640, 640]\n",
        "        yield [np.random.uniform(0.0, 1.0, size=(1, 3, 640, 640)).astype(np.float32)]"
      ],
      "metadata": {
        "id": "LTj4aRh5TYZS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_tflite_model(tflite_path, test_image_path=None):\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "\n",
        "    # Load TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    print(\"TensorFlow Lite Model Validation:\")\n",
        "    print(f\"Model path: {tflite_path}\")\n",
        "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
        "    print(f\"Input type: {input_details[0]['dtype']}\")\n",
        "    print(f\"Number of outputs: {len(output_details)}\")\n",
        "\n",
        "    for i, output in enumerate(output_details):\n",
        "        print(f\"Output {i} shape: {output['shape']}\")\n",
        "        print(f\"Output {i} type: {output['dtype']}\")\n",
        "\n",
        "    # Test with random input if no test image provided\n",
        "    if test_image_path is None:\n",
        "        input_shape = input_details[0]['shape']\n",
        "        test_input = np.random.random(input_shape).astype(input_details[0]['dtype'])\n",
        "\n",
        "        # Normalize input to [0, 1] range if float32\n",
        "        if input_details[0]['dtype'] == np.float32:\n",
        "            test_input = test_input.astype(np.float32)\n",
        "        elif input_details[0]['dtype'] == np.uint8:\n",
        "            test_input = (test_input * 255).astype(np.uint8)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
        "        interpreter.invoke()\n",
        "\n",
        "        print(\"Test inference completed successfully!\")\n",
        "\n",
        "        # Get outputs\n",
        "        for i, output in enumerate(output_details):\n",
        "            output_data = interpreter.get_tensor(output['index'])\n",
        "            print(f\"Output {i} shape: {output_data.shape}\")\n",
        "            print(f\"Output {i} min/max: {output_data.min():.4f}/{output_data.max():.4f}\")\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "upBLr45wnw52"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_model(tflite_path, num_runs=50):\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "    import time\n",
        "\n",
        "    print(f\"Benchmarking model: {tflite_path}\")\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    input_shape = input_details[0]['shape']\n",
        "    input_dtype = input_details[0]['dtype']\n",
        "\n",
        "    # Prepare test input\n",
        "    if input_dtype == np.float32:\n",
        "        test_input = np.random.random(input_shape).astype(np.float32)\n",
        "    else:\n",
        "        test_input = np.random.randint(0, 256, size=input_shape, dtype=input_dtype)\n",
        "\n",
        "    # Warm up\n",
        "    for _ in range(5):\n",
        "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
        "        interpreter.invoke()\n",
        "\n",
        "    # Benchmark\n",
        "    times = []\n",
        "    for _ in range(num_runs):\n",
        "        start_time = time.time()\n",
        "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
        "        interpreter.invoke()\n",
        "        end_time = time.time()\n",
        "        times.append((end_time - start_time) * 1000)  # Convert to ms\n",
        "\n",
        "    avg_time = np.mean(times)\n",
        "    std_time = np.std(times)\n",
        "\n",
        "    print(f\"Average inference time: {avg_time:.2f} Â± {std_time:.2f} ms\")\n",
        "    print(f\"FPS: {1000/avg_time:.1f}\")\n",
        "\n",
        "    return avg_time"
      ],
      "metadata": {
        "id": "P-Y8PlvMTe72"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"=== YOLOv5s Training and TensorFlow Lite Conversion Pipeline ===\")\n",
        "    try:\n",
        "        # Step 1: Install requirements\n",
        "        print(\"\\n1. Installing required packages...\")\n",
        "        install_requirements()\n",
        "\n",
        "        # Then run quick test\n",
        "        print(\"\\nRunning quick inference test...\")\n",
        "        quick_inference_test()\n",
        "\n",
        "        # Step 2: Check for existing dataset or prepare COCO128\n",
        "        print(\"\\n2. Checking for existing dataset...\")\n",
        "        dataset_path, yaml_path = prepare_dataset()\n",
        "\n",
        "        # Step 3: Train model\n",
        "        print(\"\\n3. Training YOLOv5s model...\")\n",
        "        model, results = train_yolov5s(yaml_path, epochs=50)  # Reduced for faster training\n",
        "\n",
        "        # Step 4: Export model formats\n",
        "        print(\"\\n4. Exporting model to different formats...\")\n",
        "        onnx_path, tf_path, torchscript_path = export_model_formats(model)\n",
        "\n",
        "        # Step 5: Convert to TensorFlow Lite\n",
        "        print(\"\\n5. Converting to TensorFlow Lite...\")\n",
        "        tflite_path = convert_to_tflite(onnx_path)\n",
        "\n",
        "        if tflite_path:\n",
        "            # Step 6: Validate TFLite model\n",
        "            print(\"\\n6. Validating TensorFlow Lite model...\")\n",
        "            validate_tflite_model(tflite_path)\n",
        "\n",
        "            # Step 7: Benchmark model\n",
        "            print(\"\\n7. Benchmarking TensorFlow Lite model...\")\n",
        "            benchmark_model(tflite_path)\n",
        "\n",
        "            print(\"\\n=== Pipeline Completed Successfully ===\")\n",
        "            print(f\"Final TensorFlow Lite model: {tflite_path}\")\n",
        "        else:\n",
        "            print(\"\\n=== Pipeline Completed with Errors ===\")\n",
        "            print(\"TensorFlow Lite conversion failed. Check the ONNX model output.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nPipeline failed with error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "F-WiBlQbn3Ab"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tflite_conversion():\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    print(\"Running simplified TensorFlow Lite conversion...\")\n",
        "\n",
        "    # Load pre-trained YOLOv5s\n",
        "    model = YOLO('yolov5s.pt')\n",
        "\n",
        "    # Direct export to TensorFlow Lite (if supported)\n",
        "    try:\n",
        "        tflite_path = model.export(format='tflite', imgsz=640)\n",
        "        print(f\"Direct TFLite export successful: {tflite_path}\")\n",
        "        return tflite_path\n",
        "    except Exception as e:\n",
        "        print(f\"Direct TFLite export failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "2YJzGee_n-D3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_inference_test():\n",
        "    \"\"\"Quick test to verify YOLOv5s is working\"\"\"\n",
        "    from ultralytics import YOLO\n",
        "    import numpy as np\n",
        "\n",
        "    print(\"Running quick YOLOv5s inference test...\")\n",
        "\n",
        "    # Load model\n",
        "    model = YOLO('yolov5s.pt')\n",
        "\n",
        "    # Create dummy image\n",
        "    dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(dummy_image)\n",
        "\n",
        "    print(\"YOLOv5s inference test completed successfully!\")\n",
        "    print(f\"Number of detections: {len(results[0].boxes) if results[0].boxes is not None else 0}\")"
      ],
      "metadata": {
        "id": "zekWonmqTqkz"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run in Google Colab environment\n",
        "    print(\"Starting YOLOv5s training and TensorFlow Lite conversion...\")\n",
        "    print(\"Note: This process may take 1-2 hours depending on training epochs and hardware.\")\n",
        "\n",
        "    # Uncomment the line below to run the full pipeline\n",
        "    main()\n",
        "\n",
        "    # For quick testing, uncomment the line below\n",
        "    simple_tflite_conversion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ4RRCuPoBLN",
        "outputId": "015d17db-4152-4dca-b9ae-f0379defbcb8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting YOLOv5s training and TensorFlow Lite conversion...\n",
            "Note: This process may take 1-2 hours depending on training epochs and hardware.\n",
            "=== YOLOv5s Training and TensorFlow Lite Conversion Pipeline ===\n",
            "\n",
            "1. Installing required packages...\n",
            "All required packages installed successfully!\n",
            "\n",
            "Running quick inference test...\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Running quick YOLOv5s inference test...\n",
            "PRO TIP ğŸ’¡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 17.7MB 98.8MB/s 0.2s\n",
            "\n",
            "0: 640x640 (no detections), 15.0ms\n",
            "Speed: 22.7ms preprocess, 15.0ms inference, 101.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "YOLOv5s inference test completed successfully!\n",
            "Number of detections: 0\n",
            "\n",
            "2. Checking for existing dataset...\n",
            "No existing dataset found. Downloading COCO128...\n",
            "Downloading COCO128 dataset...\n",
            "Extracting dataset...\n",
            "coco128.yaml not found, creating configuration...\n",
            "Created coco128.yaml at: /content/coco128/coco128.yaml\n",
            "COCO128 dataset downloaded and extracted successfully!\n",
            "\n",
            "3. Training YOLOv5s model...\n",
            "Initializing YOLOv5s model...\n",
            "PRO TIP ğŸ’¡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Starting training for 50 epochs...\n",
            "Using dataset configuration: /content/coco128/coco128.yaml\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/coco128/coco128.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov5s_experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/yolov5_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolov5_training/yolov5s_experiment, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 23.2MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
            "YOLOv5s summary: 153 layers, 9,153,152 parameters, 9,153,136 gradients, 24.2 GFLOPs\n",
            "\n",
            "Transferred 427/427 items from pretrained weights\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 96.9MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1046.4Â±652.5 MB/s, size: 50.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 2.4Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/coco128/labels/train2017.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 456.3it/s 0.3s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 414.6Â±207.0 MB/s, size: 51.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 170.5Kit/s 0.0s\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 147.3it/s 0.9s\n",
            "Plotting labels to /content/yolov5_training/yolov5s_experiment/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov5_training/yolov5s_experiment\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      3.87G      1.122      1.158       1.22        228        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.9it/s 2.1s\n",
            "                   all        128        929      0.745       0.67      0.748      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      5.41G      1.115      1.082      1.166        205        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.4it/s 1.2s\n",
            "                   all        128        929      0.771      0.686      0.763      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      5.42G      1.142      1.112      1.206        125        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.732      0.706       0.77      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      5.42G      1.082      1.015      1.172        180        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.814      0.685      0.783      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      5.42G      1.015      1.012      1.147        250        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.1it/s 1.3s\n",
            "                   all        128        929      0.836      0.681      0.784      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      5.45G      1.009     0.9727      1.145        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.855      0.691      0.802      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      5.48G      1.043     0.9484      1.132        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        128        929      0.797      0.749      0.812      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      5.52G      1.047     0.9474      1.148        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.883      0.716      0.816      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      5.52G     0.9992     0.9196      1.131        122        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.839      0.753      0.822      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      5.52G     0.9488     0.8598      1.106        175        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.847      0.757      0.826      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      5.52G     0.9946     0.8657      1.111        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.875      0.767       0.84      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      5.52G      1.004     0.8888      1.116        242        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.4it/s 1.2s\n",
            "                   all        128        929      0.883      0.764      0.844      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      5.52G     0.9371     0.8156      1.102        186        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.888      0.767      0.845      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      5.52G     0.9183     0.8075      1.103        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.891      0.768      0.853      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      5.52G     0.9323     0.7977      1.089        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.5it/s 1.1s\n",
            "                   all        128        929      0.873      0.775      0.854      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      5.52G      0.924     0.7962      1.082        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.889      0.777      0.855      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      5.55G     0.8855     0.7248      1.046        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.881      0.797       0.86      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      5.55G     0.9194     0.7563      1.059        179        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.886      0.802      0.862      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      5.55G     0.9325     0.7809      1.063        199        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.7it/s 1.1s\n",
            "                   all        128        929       0.86      0.822      0.866      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      5.55G     0.8939     0.7539      1.047        293        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.868      0.823      0.869      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      5.55G     0.8929     0.7219      1.063        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.848      0.824      0.871      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      5.55G     0.9096     0.7549      1.049        200        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.3it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.0it/s 1.3s\n",
            "                   all        128        929      0.821      0.833      0.877      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      5.55G     0.8821     0.7605      1.063        216        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929       0.86       0.82      0.878      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      5.55G     0.8718     0.7399      1.055        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.876      0.818      0.877      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      5.55G     0.8939      0.715      1.039        187        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.7it/s 1.1s\n",
            "                   all        128        929      0.868      0.821      0.877      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      5.55G     0.8516      0.701       1.02        250        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.908      0.803      0.877      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      5.55G     0.8473     0.7028      1.025        171        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.907      0.804      0.879      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      5.55G     0.8556     0.7101      1.047        249        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929       0.91      0.808       0.88      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      5.55G      0.819     0.6552      1.013        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        128        929      0.911      0.812      0.881       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      5.58G      0.884     0.6892      1.044        258        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.906      0.814       0.88      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      5.58G     0.8522     0.6826      1.019        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.904      0.814      0.878      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      5.58G     0.7888     0.6596      1.017        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.3it/s 1.2s\n",
            "                   all        128        929      0.898       0.82       0.88      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      5.58G     0.8648     0.6741      1.022        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.898      0.822      0.884      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      5.58G     0.8184     0.6731      1.033        224        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.907      0.819      0.886      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      5.58G     0.8286     0.6729      1.014        229        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        128        929      0.917      0.813      0.886      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      5.58G     0.8263     0.6388      1.006        201        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.926       0.81      0.887      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      5.58G      0.832     0.6775      1.029        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.929      0.811      0.888      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      5.58G     0.7909     0.6307          1        255        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 1.0s\n",
            "                   all        128        929      0.925      0.819       0.89      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      5.58G     0.8006     0.6279       1.01        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.4it/s 1.2s\n",
            "                   all        128        929       0.93       0.82      0.891      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      5.58G     0.7828     0.6302      1.018        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.933      0.822      0.891      0.747\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      5.58G     0.8217     0.6368     0.9855         86        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.4it/s 3.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.6it/s 1.1s\n",
            "                   all        128        929      0.934       0.82      0.892      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      5.58G     0.8403     0.6566     0.9849        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.5it/s 1.1s\n",
            "                   all        128        929      0.933      0.821      0.892      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      5.58G     0.7844     0.5971     0.9667         94        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.927      0.821      0.892      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      5.58G      0.843     0.6377     0.9941        105        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.917      0.824       0.89      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      5.58G     0.7688     0.5837     0.9588         78        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.4it/s 1.2s\n",
            "                   all        128        929      0.926      0.819      0.889      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      5.58G     0.8304     0.6504     0.9815        154        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.925      0.823      0.889       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      5.58G     0.7977     0.5856     0.9806         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 1.0s\n",
            "                   all        128        929      0.928      0.821      0.887       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      5.58G     0.7904      0.589     0.9676        103        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.928      0.821      0.888      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      5.58G      0.774     0.5644     0.9676        123        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        128        929      0.926      0.822      0.887       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      5.58G     0.7677      0.572     0.9746         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.924      0.822      0.887       0.75\n",
            "\n",
            "50 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from /content/yolov5_training/yolov5s_experiment/weights/last.pt, 18.6MB\n",
            "Optimizer stripped from /content/yolov5_training/yolov5s_experiment/weights/best.pt, 18.6MB\n",
            "\n",
            "Validating /content/yolov5_training/yolov5s_experiment/weights/best.pt...\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.8it/s 2.2s\n",
            "                   all        128        929      0.925      0.823      0.889      0.751\n",
            "                person         61        254      0.989      0.705      0.902      0.717\n",
            "               bicycle          3          6        0.8      0.667      0.788      0.508\n",
            "                   car         12         46      0.939      0.337      0.604       0.34\n",
            "            motorcycle          4          5      0.946          1      0.995      0.946\n",
            "              airplane          5          6      0.959          1      0.995      0.923\n",
            "                   bus          5          7          1      0.929      0.995      0.853\n",
            "                 train          3          3       0.94          1      0.995      0.859\n",
            "                 truck          5         12      0.912        0.5      0.681      0.501\n",
            "                  boat          2          6          1      0.733      0.838       0.74\n",
            "         traffic light          4         14       0.84      0.429      0.539      0.347\n",
            "             stop sign          2          2      0.878          1      0.995      0.946\n",
            "                 bench          5          9          1      0.972      0.995        0.8\n",
            "                  bird          2         16      0.978          1      0.995      0.819\n",
            "                   cat          4          4      0.941          1      0.995      0.973\n",
            "                   dog          9          9      0.944      0.889      0.984      0.885\n",
            "                 horse          1          2      0.912          1      0.995       0.85\n",
            "              elephant          4         17          1      0.957      0.995      0.863\n",
            "                  bear          1          1       0.81          1      0.995      0.995\n",
            "                 zebra          2          4      0.934          1      0.995      0.995\n",
            "               giraffe          4          9      0.993          1      0.995      0.919\n",
            "              backpack          4          6          1      0.805      0.838      0.646\n",
            "              umbrella          4         18          1      0.911      0.995      0.872\n",
            "               handbag          9         19      0.906      0.511      0.728      0.556\n",
            "                   tie          6          7      0.925      0.857      0.859      0.719\n",
            "              suitcase          2          4      0.932          1      0.995      0.864\n",
            "               frisbee          5          5       0.93        0.8      0.806      0.732\n",
            "                  skis          1          1      0.801          1      0.995      0.895\n",
            "             snowboard          2          7      0.832      0.857      0.893      0.753\n",
            "           sports ball          6          6      0.845      0.667      0.673       0.43\n",
            "                  kite          2         10      0.946        0.4      0.699      0.356\n",
            "          baseball bat          4          4      0.897       0.75      0.822      0.531\n",
            "        baseball glove          4          7      0.954      0.429      0.442      0.326\n",
            "            skateboard          3          5      0.765          1      0.928      0.668\n",
            "         tennis racket          5          7      0.988      0.714      0.722       0.53\n",
            "                bottle          6         18          1      0.501      0.926      0.627\n",
            "            wine glass          5         16       0.93      0.688      0.913      0.667\n",
            "                   cup         10         36      0.885      0.861      0.903      0.692\n",
            "                  fork          6          6          1      0.731      0.972      0.806\n",
            "                 knife          7         16          1      0.711      0.899      0.653\n",
            "                 spoon          5         22      0.898      0.727      0.783      0.562\n",
            "                  bowl          9         28          1      0.809      0.905      0.765\n",
            "                banana          1          1      0.823          1      0.995      0.995\n",
            "              sandwich          2          2      0.859          1      0.995      0.947\n",
            "                orange          1          4      0.847          1      0.995      0.807\n",
            "              broccoli          4         11      0.866      0.545      0.698      0.522\n",
            "                carrot          3         24      0.957      0.926      0.959      0.734\n",
            "               hot dog          1          2      0.862          1      0.995      0.995\n",
            "                 pizza          5          5      0.975          1      0.995      0.976\n",
            "                 donut          2         14      0.868      0.943      0.976      0.938\n",
            "                  cake          4          4      0.929          1      0.995      0.972\n",
            "                 chair          9         35          1      0.618      0.939      0.718\n",
            "                 couch          5          6      0.852          1      0.995      0.831\n",
            "          potted plant          9         14          1      0.966      0.995      0.818\n",
            "                   bed          3          3       0.96          1      0.995      0.963\n",
            "          dining table         10         13      0.952      0.846       0.98      0.802\n",
            "                toilet          2          2      0.885          1      0.995      0.922\n",
            "                    tv          2          2       0.87          1      0.995      0.995\n",
            "                laptop          2          3      0.921          1      0.995      0.941\n",
            "                 mouse          2          2      0.849        0.5       0.62      0.449\n",
            "                remote          5          8          1       0.67      0.753      0.626\n",
            "            cell phone          5          8      0.867      0.625      0.669      0.481\n",
            "             microwave          3          3       0.91          1      0.995      0.995\n",
            "                  oven          5          5      0.681        0.6      0.669      0.548\n",
            "                  sink          4          6          1      0.964      0.995       0.85\n",
            "          refrigerator          5          5      0.945          1      0.995      0.915\n",
            "                  book          6         29          1      0.503      0.799      0.541\n",
            "                 clock          8          9          1      0.953      0.995      0.839\n",
            "                  vase          2          2      0.906          1      0.995      0.995\n",
            "              scissors          1          1          1          0      0.199     0.0796\n",
            "            teddy bear          6         21          1      0.899      0.995       0.84\n",
            "            toothbrush          2          5      0.936          1      0.995      0.872\n",
            "Speed: 0.2ms preprocess, 4.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolov5_training/yolov5s_experiment\u001b[0m\n",
            "Training completed!\n",
            "\n",
            "4. Exporting model to different formats...\n",
            "Exporting YOLOv5s model to different formats...\n",
            "Exporting to ONNX...\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov5_training/yolov5s_experiment/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.67', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 8.3s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.69...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 10.3s, saved as '/content/yolov5_training/yolov5s_experiment/weights/best.onnx' (35.1 MB)\n",
            "\n",
            "Export complete (11.1s)\n",
            "Results saved to \u001b[1m/content/yolov5_training/yolov5s_experiment/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best.onnx imgsz=640 data=/content/coco128/coco128.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ONNX model exported to: /content/yolov5_training/yolov5s_experiment/weights/best.onnx\n",
            "Exporting to TorchScript...\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov5_training/yolov5s_experiment/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.8.0+cu126...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 2.8s, saved as '/content/yolov5_training/yolov5s_experiment/weights/best.torchscript' (35.4 MB)\n",
            "\n",
            "Export complete (3.6s)\n",
            "Results saved to \u001b[1m/content/yolov5_training/yolov5s_experiment/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best.torchscript imgsz=640 data=/content/coco128/coco128.yaml  \n",
            "Visualize:       https://netron.app\n",
            "TorchScript model exported to: /content/yolov5_training/yolov5s_experiment/weights/best.torchscript\n",
            "Exporting to TensorFlow SavedModel...\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov5_training/yolov5s_experiment/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 3.4s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 32.5MB/s 0.0s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.2files/s 0.0s\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.69...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as '/content/yolov5_training/yolov5s_experiment/weights/best.onnx' (35.1 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at '/content/yolov5_training/yolov5s_experiment/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 84, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136373738305296: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373738305872: TensorSpec(shape=(6, 6, 3, 32), dtype=tf.float32, name=None)\n",
            "  136373738305488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373738307216: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373738306832: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136373461191376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461190992: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  136373461192144: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373461192720: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136373461193104: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373461192912: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136373461192528: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  136373461193296: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373461192336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373461191952: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373461193488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461194256: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373461193872: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136373461194064: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461194640: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136373461194832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461195408: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373461195792: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461195600: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373461195984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461196176: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373461196560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461194448: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373461195216: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136373461196752: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461195024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373461197328: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461196368: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461197520: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373461196944: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136373461197136: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461197904: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373461198096: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461198672: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461199056: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461198864: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461199248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461199440: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461199824: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461197712: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461200016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461200208: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461200592: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461199632: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373461198480: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373461200784: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461198288: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373461201360: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373461200400: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461201552: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373461200976: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  136373461201168: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373461201936: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373461202128: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461202704: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373461203088: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461202896: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373461202512: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373461203280: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461202320: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461203856: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136373461201744: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373461203472: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373461204048: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461204432: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
            "  136373461204624: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373461204240: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373461203664: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373461204816: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
            "  136373399421200: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399421776: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399422160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399421584: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
            "  136373399421968: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399421392: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399422352: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399422736: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373399422928: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399422544: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373399423120: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399423696: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  136373399423312: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399424080: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399424464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399423888: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  136373399424272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399423504: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399424656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399425040: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399425232: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399425424: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373399424848: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399421008: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399427536: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373399426960: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399429072: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399428112: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399427920: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373399430992: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399427344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399430608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399431184: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373399430032: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399430800: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373399428880: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373399429456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399432336: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373399431760: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399433872: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373399432912: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399432720: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373399434640: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373399432144: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399435024: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373399435600: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136373399434256: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373399435792: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
            "  136373399434832: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
            "  136373399429840: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373399429264: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136373399426384: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399426000: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136373399435984: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399433680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399430416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399429648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399425616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399425808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399436176: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399435408: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399431952: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399430224: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399427152: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373399426192: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399435216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399434064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399431568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399431376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399426768: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373399426576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399436944: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136373399436368: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399433488: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136373399432528: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399428688: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136373399427728: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373399436752: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399436560: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136373399433104: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399433296: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136373399428304: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373399428496: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136372303577360: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303578320: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373399434448: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136372303579280: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303580048: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303580240: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303579664: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303578896: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136372303580624: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136372303577936: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303577744: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 27.5s, saved as '/content/yolov5_training/yolov5s_experiment/weights/best_saved_model' (87.8 MB)\n",
            "\n",
            "Export complete (28.2s)\n",
            "Results saved to \u001b[1m/content/yolov5_training/yolov5s_experiment/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best_saved_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/yolov5_training/yolov5s_experiment/weights/best_saved_model imgsz=640 data=/content/coco128/coco128.yaml  \n",
            "Visualize:       https://netron.app\n",
            "TensorFlow SavedModel exported to: /content/yolov5_training/yolov5s_experiment/weights/best_saved_model\n",
            "\n",
            "5. Converting to TensorFlow Lite...\n",
            "Converting ONNX to TensorFlow SavedModel...\n",
            "Converting TensorFlow SavedModel to TensorFlow Lite...\n",
            "TensorFlow Lite model saved to: /content/tflite_models/yolov5s_coco128.tflite\n",
            "TensorFlow Lite model size: 17.56 MB\n",
            "\n",
            "6. Validating TensorFlow Lite model...\n",
            "TensorFlow Lite Model Validation:\n",
            "Model path: /content/tflite_models/yolov5s_coco128.tflite\n",
            "Input shape: [  1 640 640   3]\n",
            "Input type: <class 'numpy.float32'>\n",
            "Number of outputs: 1\n",
            "Output 0 shape: [   1   84 8400]\n",
            "Output 0 type: <class 'numpy.float32'>\n",
            "Test inference completed successfully!\n",
            "Output 0 shape: (1, 84, 8400)\n",
            "Output 0 min/max: 0.0000/636.8339\n",
            "\n",
            "7. Benchmarking TensorFlow Lite model...\n",
            "Benchmarking model: /content/tflite_models/yolov5s_coco128.tflite\n",
            "Average inference time: 334.72 Â± 44.19 ms\n",
            "FPS: 3.0\n",
            "\n",
            "=== Pipeline Completed Successfully ===\n",
            "Final TensorFlow Lite model: /content/tflite_models/yolov5s_coco128.tflite\n",
            "Running simplified TensorFlow Lite conversion...\n",
            "PRO TIP ğŸ’¡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Ultralytics 8.3.203 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov5su.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.69...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as 'yolov5su.onnx' (35.2 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at 'yolov5su_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 84, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136373750577872: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373750577296: TensorSpec(shape=(6, 6, 3, 32), dtype=tf.float32, name=None)\n",
            "  136373750578448: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373750577104: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373750578256: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136373750578640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750577680: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  136373750577488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373750576528: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136373750576144: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373750576336: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136373750576720: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  136373750575952: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373750576912: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136373750575376: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373750578064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750575184: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373750575760: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  136373750575568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750574992: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136373750574800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750574224: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373750573840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750574032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373750573648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750573456: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373750573072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750579024: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136373750574416: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136373750572880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750574608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136373750572304: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750573264: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750572112: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373750572688: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  136373750572496: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750571728: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373750571536: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750570960: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750570576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750570768: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750570384: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750570192: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750569808: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750571920: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750569616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750569424: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750569040: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750570000: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750571152: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373750568848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750571344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750568272: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373750569232: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750568080: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136373750568656: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
            "  136373750568464: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373750567504: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373750567312: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750566736: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373750566352: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750566544: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373750566928: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373750566160: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750567120: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750565584: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136373750567888: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373750565968: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373750565392: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750565200: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
            "  136373750564816: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136373750565008: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136373750564624: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750564048: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
            "  136373750564432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750563664: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750563280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750563856: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
            "  136373750563472: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136373750564240: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373750563088: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136373746374928: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136373750565776: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136373750562896: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136373756646928: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303592720: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  136372303593296: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303592336: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303591952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303592528: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  136372303592144: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303592912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303591760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303591376: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303591184: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303590992: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136372303591568: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303593104: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303588880: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136372303589456: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303587344: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303588304: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303588496: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136372303585232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303589072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303585808: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303585424: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136372303586384: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303586192: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136372303587536: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136372303586960: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303581968: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136372303584272: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303581392: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136372303582544: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303582928: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136372303580048: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
            "  136372303583504: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303579856: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136372303577936: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
            "  136372303578320: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
            "  136372303577744: TensorSpec(shape=(3, 3, 512, 128), dtype=tf.float32, name=None)\n",
            "  136372303580240: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
            "  136372303586576: TensorSpec(shape=(3, 3, 256, 128), dtype=tf.float32, name=None)\n",
            "  136372303587152: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136372303590032: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303590416: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136372303579664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303580432: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303586000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303586768: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303590800: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303590608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303580816: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303580624: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303584464: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303585616: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303589264: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136372303590224: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303578896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303577360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303584080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303584656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303589648: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136372303589840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303578704: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136372303579088: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303582160: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136372303583120: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303587728: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136372303588688: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136372303581584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303578512: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136372303585040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303584848: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136372303588112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136372303587920: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136373738300496: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738300304: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136372303579472: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136373738306832: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738301456: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738301072: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738305872: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738306256: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136373738307024: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136373738299920: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136373738300880: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 14.3s, saved as 'yolov5su_saved_model' (88.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'yolov5su_saved_model/yolov5su_float32.tflite' (35.1 MB)\n",
            "\n",
            "Export complete (15.1s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov5su_saved_model/yolov5su_float32.tflite imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov5su_saved_model/yolov5su_float32.tflite imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Direct TFLite export successful: yolov5su_saved_model/yolov5su_float32.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create zip of entire content folder\n",
        "print(\"Creating backup of content folder...\")\n",
        "!zip -r /content/colab_content.zip /content/ -x \"*.zip\" \"*/.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJHu-L1pawru",
        "outputId": "34e561b6-e89e-4258-a111-adb3d1931478"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating backup of content folder...\n",
            "  adding: content/ (stored 0%)\n",
            "  adding: content/yolov5_training/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/labels.jpg (deflated 24%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch320.jpg (deflated 9%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch2_labels.jpg (deflated 10%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch0.jpg (deflated 3%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/BoxP_curve.png (deflated 10%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch321.jpg (deflated 9%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/confusion_matrix.png (deflated 21%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch1.jpg (deflated 3%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/args.yaml (deflated 53%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/BoxR_curve.png (deflated 9%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch1_labels.jpg (deflated 6%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/BoxPR_curve.png (deflated 11%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch2_pred.jpg (deflated 10%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/confusion_matrix_normalized.png (deflated 21%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/results.png (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/BoxF1_curve.png (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/results.csv (deflated 61%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch0_pred.jpg (deflated 7%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch322.jpg (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/train_batch2.jpg (deflated 2%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/epoch30.pt (deflated 28%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/epoch10.pt (deflated 30%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/epoch40.pt (deflated 27%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best.onnx (deflated 15%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best.torchscript (deflated 16%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/variables/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/variables/variables.data-00000-of-00001 (deflated 86%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/variables/variables.index (deflated 33%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/metadata.yaml (deflated 45%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/best_float16.tflite (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/assets/ (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/best_float32.tflite (deflated 15%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/saved_model.pb (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best_saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/epoch20.pt (deflated 28%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/best.pt (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/last.pt (deflated 8%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/weights/epoch0.pt (deflated 34%)\n",
            "  adding: content/yolov5_training/yolov5s_experiment/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/calibration_image_sample_data_20x128x128x3_float32.npy (deflated 70%)\n",
            "  adding: content/tflite_models/ (stored 0%)\n",
            "  adding: content/tflite_models/yolov5s_coco128.tflite (deflated 8%)\n",
            "  adding: content/tflite_models/saved_model/ (stored 0%)\n",
            "  adding: content/tflite_models/saved_model/variables/ (stored 0%)\n",
            "  adding: content/tflite_models/saved_model/variables/variables.data-00000-of-00001 (deflated 86%)\n",
            "  adding: content/tflite_models/saved_model/variables/variables.index (deflated 33%)\n",
            "  adding: content/tflite_models/saved_model/best_float16.tflite (deflated 8%)\n",
            "  adding: content/tflite_models/saved_model/assets/ (stored 0%)\n",
            "  adding: content/tflite_models/saved_model/best_float32.tflite (deflated 15%)\n",
            "  adding: content/tflite_models/saved_model/saved_model.pb (deflated 8%)\n",
            "  adding: content/tflite_models/saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/yolov5su.pt (deflated 8%)\n",
            "  adding: content/yolov5su_saved_model/ (stored 0%)\n",
            "  adding: content/yolov5su_saved_model/variables/ (stored 0%)\n",
            "  adding: content/yolov5su_saved_model/variables/variables.data-00000-of-00001 (deflated 86%)\n",
            "  adding: content/yolov5su_saved_model/variables/variables.index (deflated 33%)\n",
            "  adding: content/yolov5su_saved_model/metadata.yaml (deflated 45%)\n",
            "  adding: content/yolov5su_saved_model/assets/ (stored 0%)\n",
            "  adding: content/yolov5su_saved_model/saved_model.pb (deflated 8%)\n",
            "  adding: content/yolov5su_saved_model/yolov5su_float32.tflite (deflated 15%)\n",
            "  adding: content/yolov5su_saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/yolov5su_saved_model/yolov5su_float16.tflite (deflated 8%)\n",
            "  adding: content/yolov5su.onnx (deflated 16%)\n",
            "  adding: content/coco128/ (stored 0%)\n",
            "  adding: content/coco128/README.txt (deflated 40%)\n",
            "  adding: content/coco128/coco128.yaml (deflated 51%)\n",
            "  adding: content/coco128/images/ (stored 0%)\n",
            "  adding: content/coco128/images/train2017/ (stored 0%)\n",
            "  adding: content/coco128/images/train2017/000000000387.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000073.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000133.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000397.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000540.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000597.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000307.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000589.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000025.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000283.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000089.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000368.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000590.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000009.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000415.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000257.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000294.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000360.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000143.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000581.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000086.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000194.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000074.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000431.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000450.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000508.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000136.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000643.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000486.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000072.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000605.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000529.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000201.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000092.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000315.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000531.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000382.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000144.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000491.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000520.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000436.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000247.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000322.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000400.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000626.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000061.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000357.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000404.jpg (deflated 3%)\n",
            "  adding: content/coco128/images/train2017/000000000419.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000263.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000595.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000042.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000078.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000472.jpg (deflated 5%)\n",
            "  adding: content/coco128/images/train2017/000000000625.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000196.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000562.jpg (deflated 3%)\n",
            "  adding: content/coco128/images/train2017/000000000164.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000446.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000514.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000138.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000575.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000474.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000623.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000030.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000077.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000149.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000459.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000542.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000395.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000109.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000612.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000394.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000071.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000142.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000308.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000309.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000338.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000250.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000490.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000536.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000260.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000328.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000332.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000443.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000064.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000510.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000034.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000389.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000312.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000151.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000049.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000560.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000036.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000488.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000321.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000599.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000110.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000438.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000564.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000634.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000532.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000081.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000572.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000094.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000584.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000154.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000165.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000359.jpg (deflated 4%)\n",
            "  adding: content/coco128/images/train2017/000000000370.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000326.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000636.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000192.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000349.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000127.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000208.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000471.jpg (deflated 2%)\n",
            "  adding: content/coco128/images/train2017/000000000241.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000113.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000629.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000502.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000641.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000384.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000650.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000544.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000428.jpg (deflated 1%)\n",
            "  adding: content/coco128/images/train2017/000000000569.jpg (deflated 0%)\n",
            "  adding: content/coco128/images/train2017/000000000620.jpg (deflated 0%)\n",
            "  adding: content/coco128/LICENSE (deflated 66%)\n",
            "  adding: content/coco128/labels/ (stored 0%)\n",
            "  adding: content/coco128/labels/train2017.cache (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/ (stored 0%)\n",
            "  adding: content/coco128/labels/train2017/000000000584.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000338.txt (deflated 47%)\n",
            "  adding: content/coco128/labels/train2017/000000000089.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000143.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000404.txt (deflated 46%)\n",
            "  adding: content/coco128/labels/train2017/000000000165.txt (deflated 42%)\n",
            "  adding: content/coco128/labels/train2017/000000000532.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000491.txt (deflated 45%)\n",
            "  adding: content/coco128/labels/train2017/000000000201.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000581.txt (deflated 14%)\n",
            "  adding: content/coco128/labels/train2017/000000000625.txt (deflated 41%)\n",
            "  adding: content/coco128/labels/train2017/000000000072.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000030.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000612.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000514.txt (deflated 8%)\n",
            "  adding: content/coco128/labels/train2017/000000000208.txt (deflated 42%)\n",
            "  adding: content/coco128/labels/train2017/000000000136.txt (deflated 43%)\n",
            "  adding: content/coco128/labels/train2017/000000000241.txt (deflated 54%)\n",
            "  adding: content/coco128/labels/train2017/000000000370.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000428.txt (deflated 37%)\n",
            "  adding: content/coco128/labels/train2017/000000000605.txt (deflated 41%)\n",
            "  adding: content/coco128/labels/train2017/000000000575.txt (deflated 5%)\n",
            "  adding: content/coco128/labels/train2017/000000000263.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000092.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000540.txt (deflated 59%)\n",
            "  adding: content/coco128/labels/train2017/000000000471.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000384.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000151.txt (deflated 37%)\n",
            "  adding: content/coco128/labels/train2017/000000000042.txt (deflated 9%)\n",
            "  adding: content/coco128/labels/train2017/000000000194.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000142.txt (deflated 42%)\n",
            "  adding: content/coco128/labels/train2017/000000000009.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000110.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000597.txt (deflated 51%)\n",
            "  adding: content/coco128/labels/train2017/000000000247.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000260.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000307.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000450.txt (deflated 42%)\n",
            "  adding: content/coco128/labels/train2017/000000000113.txt (deflated 56%)\n",
            "  adding: content/coco128/labels/train2017/000000000077.txt (deflated 51%)\n",
            "  adding: content/coco128/labels/train2017/000000000589.txt (deflated 27%)\n",
            "  adding: content/coco128/labels/train2017/000000000094.txt (deflated 29%)\n",
            "  adding: content/coco128/labels/train2017/000000000502.txt (deflated 8%)\n",
            "  adding: content/coco128/labels/train2017/000000000415.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000510.txt (deflated 39%)\n",
            "  adding: content/coco128/labels/train2017/000000000446.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000144.txt (deflated 39%)\n",
            "  adding: content/coco128/labels/train2017/000000000395.txt (deflated 54%)\n",
            "  adding: content/coco128/labels/train2017/000000000488.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000025.txt (deflated 27%)\n",
            "  adding: content/coco128/labels/train2017/000000000164.txt (deflated 60%)\n",
            "  adding: content/coco128/labels/train2017/000000000074.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000490.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000626.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000294.txt (deflated 58%)\n",
            "  adding: content/coco128/labels/train2017/000000000192.txt (deflated 45%)\n",
            "  adding: content/coco128/labels/train2017/000000000332.txt (deflated 50%)\n",
            "  adding: content/coco128/labels/train2017/000000000127.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000360.txt (deflated 36%)\n",
            "  adding: content/coco128/labels/train2017/000000000656.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000321.txt (deflated 40%)\n",
            "  adding: content/coco128/labels/train2017/000000000368.txt (deflated 56%)\n",
            "  adding: content/coco128/labels/train2017/000000000349.txt (deflated 44%)\n",
            "  adding: content/coco128/labels/train2017/000000000081.txt (deflated 8%)\n",
            "  adding: content/coco128/labels/train2017/000000000078.txt (deflated 8%)\n",
            "  adding: content/coco128/labels/train2017/000000000520.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000034.txt (deflated 10%)\n",
            "  adding: content/coco128/labels/train2017/000000000569.txt (deflated 48%)\n",
            "  adding: content/coco128/labels/train2017/000000000542.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000529.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000636.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000283.txt (deflated 47%)\n",
            "  adding: content/coco128/labels/train2017/000000000328.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000650.txt (deflated 29%)\n",
            "  adding: content/coco128/labels/train2017/000000000315.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000474.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000196.txt (deflated 59%)\n",
            "  adding: content/coco128/labels/train2017/000000000472.txt (deflated 11%)\n",
            "  adding: content/coco128/labels/train2017/000000000634.txt (deflated 48%)\n",
            "  adding: content/coco128/labels/train2017/000000000397.txt (deflated 49%)\n",
            "  adding: content/coco128/labels/train2017/000000000309.txt (deflated 44%)\n",
            "  adding: content/coco128/labels/train2017/000000000382.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000560.txt (deflated 47%)\n",
            "  adding: content/coco128/labels/train2017/000000000064.txt (deflated 43%)\n",
            "  adding: content/coco128/labels/train2017/000000000544.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000659.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000419.txt (deflated 51%)\n",
            "  adding: content/coco128/labels/train2017/000000000389.txt (deflated 55%)\n",
            "  adding: content/coco128/labels/train2017/000000000394.txt (deflated 31%)\n",
            "  adding: content/coco128/labels/train2017/000000000486.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000154.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000359.txt (deflated 44%)\n",
            "  adding: content/coco128/labels/train2017/000000000257.txt (deflated 59%)\n",
            "  adding: content/coco128/labels/train2017/000000000138.txt (deflated 50%)\n",
            "  adding: content/coco128/labels/train2017/000000000308.txt (deflated 54%)\n",
            "  adding: content/coco128/labels/train2017/000000000641.txt (deflated 56%)\n",
            "  adding: content/coco128/labels/train2017/000000000073.txt (deflated 29%)\n",
            "  adding: content/coco128/labels/train2017/000000000322.txt (deflated 30%)\n",
            "  adding: content/coco128/labels/train2017/000000000443.txt (deflated 49%)\n",
            "  adding: content/coco128/labels/train2017/000000000564.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000595.txt (deflated 10%)\n",
            "  adding: content/coco128/labels/train2017/000000000071.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000572.txt (deflated 37%)\n",
            "  adding: content/coco128/labels/train2017/000000000459.txt (deflated 29%)\n",
            "  adding: content/coco128/labels/train2017/000000000590.txt (deflated 25%)\n",
            "  adding: content/coco128/labels/train2017/000000000387.txt (deflated 38%)\n",
            "  adding: content/coco128/labels/train2017/000000000109.txt (deflated 51%)\n",
            "  adding: content/coco128/labels/train2017/000000000431.txt (deflated 37%)\n",
            "  adding: content/coco128/labels/train2017/000000000562.txt (deflated 44%)\n",
            "  adding: content/coco128/labels/train2017/000000000312.txt (deflated 49%)\n",
            "  adding: content/coco128/labels/train2017/000000000623.txt (deflated 44%)\n",
            "  adding: content/coco128/labels/train2017/000000000438.txt (deflated 58%)\n",
            "  adding: content/coco128/labels/train2017/000000000357.txt (deflated 56%)\n",
            "  adding: content/coco128/labels/train2017/000000000599.txt (deflated 47%)\n",
            "  adding: content/coco128/labels/train2017/000000000620.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000061.txt (deflated 47%)\n",
            "  adding: content/coco128/labels/train2017/000000000326.txt (deflated 27%)\n",
            "  adding: content/coco128/labels/train2017/000000000086.txt (deflated 37%)\n",
            "  adding: content/coco128/labels/train2017/000000000149.txt (deflated 58%)\n",
            "  adding: content/coco128/labels/train2017/000000000133.txt (deflated 28%)\n",
            "  adding: content/coco128/labels/train2017/000000000536.txt (deflated 53%)\n",
            "  adding: content/coco128/labels/train2017/000000000629.txt (deflated 8%)\n",
            "  adding: content/coco128/labels/train2017/000000000531.txt (deflated 57%)\n",
            "  adding: content/coco128/labels/train2017/000000000400.txt (deflated 26%)\n",
            "  adding: content/coco128/labels/train2017/000000000049.txt (deflated 52%)\n",
            "  adding: content/coco128/labels/train2017/000000000036.txt (deflated 27%)\n",
            "  adding: content/coco128/labels/train2017/000000000436.txt (deflated 29%)\n",
            "  adding: content/coco128/labels/train2017/000000000643.txt (deflated 59%)\n",
            "  adding: content/yolo11n.pt (deflated 11%)\n",
            "  adding: content/exported_models/ (stored 0%)\n"
          ]
        }
      ]
    }
  ]
}