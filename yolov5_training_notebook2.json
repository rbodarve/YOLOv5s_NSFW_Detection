{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv5s Training & Export for Android Real-time Detection\n",
        "\n",
        "This notebook sets up, trains, and exports a YOLOv5s model for Android real-time detection applications.\n",
        "\n",
        "## Requirements\n",
        "- Python 3.12\n",
        "- CUDA-compatible GPU (recommended)\n",
        "- Dataset in YOLO format\n",
        "\n",
        "## Model Configuration\n",
        "- **Model**: YOLOv5s (small variant)\n",
        "- **Image Size**: 640x640\n",
        "- **Batch Size**: 16\n",
        "- **Epochs**: 100\n",
        "- **Classes**: nsfw, gore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Check Python version\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install pandas\n",
        "!pip install pillow\n",
        "!pip install pyyaml\n",
        "!pip install tensorboard\n",
        "!pip install onnx\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup Folder Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create main Thesis directory and subdirectories\n",
        "base_dir = Path(\"Thesis\")\n",
        "folders = {\n",
        "    \"dataset\": [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"],\n",
        "    \"input\": [],\n",
        "    \"output\": [],\n",
        "    \"metrics\": [],\n",
        "    \"models\": []\n",
        "}\n",
        "\n",
        "# Create folder structure\n",
        "for main_folder, subfolders in folders.items():\n",
        "    main_path = base_dir / main_folder\n",
        "    main_path.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created: {main_path}\")\n",
        "    \n",
        "    for subfolder in subfolders:\n",
        "        sub_path = main_path / subfolder\n",
        "        sub_path.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"  Created: {sub_path}\")\n",
        "\n",
        "print(\"\\nFolder structure created successfully!\")\n",
        "print(\"\\nPlease ensure you have:\")\n",
        "print(\"- Training images in: Thesis/dataset/images/train/\")\n",
        "print(\"- Validation images in: Thesis/dataset/images/val/\")\n",
        "print(\"- Training labels in: Thesis/dataset/labels/train/\")\n",
        "print(\"- Validation labels in: Thesis/dataset/labels/val/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Dataset Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Create data.yaml configuration file\n",
        "data_config = {\n",
        "    'train': 'dataset/images/train',\n",
        "    'val': 'dataset/images/val',\n",
        "    'nc': 2,  # number of classes\n",
        "    'names': ['nsfw', 'gore']\n",
        "}\n",
        "\n",
        "# Save data.yaml in dataset folder\n",
        "data_yaml_path = base_dir / \"dataset\" / \"data.yaml\"\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"Dataset configuration saved to: {data_yaml_path}\")\n",
        "print(\"\\nDataset configuration:\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Clone and Setup YOLOv5 Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Clone YOLOv5 repository if it doesn't exist\n",
        "yolo_dir = \"yolov5\"\n",
        "if not os.path.exists(yolo_dir):\n",
        "    !git clone https://github.com/ultralytics/yolov5.git\n",
        "    print(\"YOLOv5 repository cloned successfully!\")\n",
        "else:\n",
        "    print(\"YOLOv5 repository already exists.\")\n",
        "\n",
        "# Change to YOLOv5 directory and install requirements\n",
        "os.chdir(yolo_dir)\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(\"\\nYOLOv5 setup completed!\")\n",
        "print(f\"Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Verify Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Go back to main directory\n",
        "os.chdir('..')\n",
        "\n",
        "# Check dataset structure and count files\n",
        "dataset_base = Path(\"Thesis/dataset\")\n",
        "\n",
        "def count_files(directory, extension):\n",
        "    return len(list(directory.glob(f\"*.{extension}\")))\n",
        "\n",
        "# Count training and validation files\n",
        "train_images = count_files(dataset_base / \"images/train\", \"jpg\") + count_files(dataset_base / \"images/train\", \"png\")\n",
        "val_images = count_files(dataset_base / \"images/val\", \"jpg\") + count_files(dataset_base / \"images/val\", \"png\")\n",
        "train_labels = count_files(dataset_base / \"labels/train\", \"txt\")\n",
        "val_labels = count_files(dataset_base / \"labels/val\", \"txt\")\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(f\"Training images: {train_images}\")\n",
        "print(f\"Training labels: {train_labels}\")\n",
        "print(f\"Validation images: {val_images}\")\n",
        "print(f\"Validation labels: {val_labels}\")\n",
        "\n",
        "if train_images == 0 or val_images == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: No images found! Please add your dataset before proceeding.\")\n",
        "    print(\"Expected format:\")\n",
        "    print(\"- Images: .jpg or .png files\")\n",
        "    print(\"- Labels: .txt files with YOLO format (class_id x_center y_center width height)\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ Dataset verification completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train YOLOv5s Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Check GPU availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "if device == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "# Training configuration\n",
        "img_size = 640\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "data_path = \"../Thesis/dataset/data.yaml\"\n",
        "project_name = \"../Thesis/models\"\n",
        "experiment_name = f\"yolov5s_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"Model: YOLOv5s\")\n",
        "print(f\"Image size: {img_size}\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Dataset: {data_path}\")\n",
        "print(f\"Output directory: {project_name}/{experiment_name}\")\n",
        "\n",
        "# Start training\n",
        "print(\"\\nüöÄ Starting training...\")\n",
        "os.chdir('yolov5')\n",
        "\n",
        "training_command = [\n",
        "    'python', 'train.py',\n",
        "    '--img', str(img_size),\n",
        "    '--batch', str(batch_size),\n",
        "    '--epochs', str(epochs),\n",
        "    '--data', data_path,\n",
        "    '--weights', 'yolov5s.pt',\n",
        "    '--project', project_name,\n",
        "    '--name', experiment_name,\n",
        "    '--save-period', '10',\n",
        "    '--device', device\n",
        "]\n",
        "\n",
        "!python train.py --img 640 --batch 16 --epochs 100 --data ../Thesis/dataset/data.yaml --weights yolov5s.pt --project ../Thesis/models --name yolov5s_training --save-period 10 --device 0\n",
        "\n",
        "print(\"\\n‚úÖ Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Validate Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "# Find the trained model weights\n",
        "weights_pattern = \"../Thesis/models/yolov5s_training*/weights/best.pt\"\n",
        "weight_files = glob.glob(weights_pattern)\n",
        "\n",
        "if weight_files:\n",
        "    best_weights = weight_files[0]  # Take the most recent training\n",
        "    print(f\"Found trained weights: {best_weights}\")\n",
        "    \n",
        "    # Run validation\n",
        "    print(\"\\nüîç Running validation...\")\n",
        "    !python val.py --weights {best_weights} --data ../Thesis/dataset/data.yaml --img 640 --save-txt --save-conf --project ../Thesis/metrics --name validation_results\n",
        "    \n",
        "    print(\"\\n‚úÖ Validation completed!\")\n",
        "    print(\"Results saved in: ../Thesis/metrics/validation_results/\")\n",
        "else:\n",
        "    print(\"‚ùå No trained weights found. Please complete training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Display Training Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# Find training results directory\n",
        "results_pattern = \"../Thesis/models/yolov5s_training*/\"\n",
        "results_dirs = glob.glob(results_pattern)\n",
        "\n",
        "if results_dirs:\n",
        "    results_dir = results_dirs[0]\n",
        "    print(f\"Loading results from: {results_dir}\")\n",
        "    \n",
        "    # Display training curves if available\n",
        "    results_img = os.path.join(results_dir, \"results.png\")\n",
        "    if os.path.exists(results_img):\n",
        "        print(\"\\nüìä Training Results:\")\n",
        "        img = Image.open(results_img)\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('Training Metrics Over Time')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Display confusion matrix if available\n",
        "    confusion_matrix_img = os.path.join(results_dir, \"confusion_matrix.png\")\n",
        "    if os.path.exists(confusion_matrix_img):\n",
        "        print(\"\\nüéØ Confusion Matrix:\")\n",
        "        img = Image.open(confusion_matrix_img)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Read and display final metrics\n",
        "    results_file = os.path.join(results_dir, \"results.txt\")\n",
        "    if os.path.exists(results_file):\n",
        "        print(\"\\nüìà Final Training Metrics:\")\n",
        "        try:\n",
        "            df = pd.read_csv(results_file, sep='\\s+', header=None)\n",
        "            if len(df) > 0:\n",
        "                last_row = df.iloc[-1]\n",
        "                print(f\"Final Epoch: {int(last_row[0]) + 1}\")\n",
        "                print(f\"mAP@0.5: {last_row[6]:.4f}\")\n",
        "                print(f\"mAP@0.5:0.95: {last_row[7]:.4f}\")\n",
        "                print(f\"Precision: {last_row[4]:.4f}\")\n",
        "                print(f\"Recall: {last_row[5]:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not parse results file: {e}\")\n",
        "            with open(results_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                if lines:\n",
        "                    print(\"Last few lines of results:\")\n",
        "                    for line in lines[-5:]:\n",
        "                        print(line.strip())\n",
        "else:\n",
        "    print(\"‚ùå No training results found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Export Model to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Find the best trained weights\n",
        "weights_pattern = \"../Thesis/models/yolov5s_training*/weights/best.pt\"\n",
        "weight_files = glob.glob(weights_pattern)\n",
        "\n",
        "if weight_files:\n",
        "    best_weights = weight_files[0]\n",
        "    print(f\"Exporting model from: {best_weights}\")\n",
        "    \n",
        "    # Export to ONNX\n",
        "    print(\"\\nüîÑ Exporting to ONNX format...\")\n",
        "    onnx_output = \"../Thesis/models/yolov5s_best.onnx\"\n",
        "    \n",
        "    export_command = [\n",
        "        'python', 'export.py',\n",
        "        '--weights', best_weights,\n",
        "        '--include', 'onnx',\n",
        "        '--img', '640',\n",
        "        '--batch', '1',\n",
        "        '--device', 'cpu',\n",
        "        '--simplify'\n",
        "    ]\n",
        "    \n",
        "    !python export.py --weights {best_weights} --include onnx --img 640 --batch 1 --device cpu --simplify\n",
        "    \n",
        "    # Move ONNX file to models directory\n",
        "    source_onnx = best_weights.replace('best.pt', 'best.onnx')\n",
        "    if os.path.exists(source_onnx):\n",
        "        import shutil\n",
        "        shutil.copy2(source_onnx, onnx_output)\n",
        "        print(f\"‚úÖ ONNX model saved to: {onnx_output}\")\n",
        "    else:\n",
        "        print(f\"‚ùå ONNX export failed. Expected file: {source_onnx}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå No trained weights found. Please complete training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Convert ONNX to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import onnx\n",
        "import os\n",
        "\n",
        "# Go back to main directory\n",
        "os.chdir('..')\n",
        "\n",
        "onnx_path = \"Thesis/models/yolov5s_best.onnx\"\n",
        "tflite_path = \"Thesis/models/yolov5s_best.tflite\"\n",
        "saved_model_path = \"Thesis/models/yolov5s_saved_model\"\n",
        "\n",
        "if os.path.exists(onnx_path):\n",
        "    print(f\"Converting ONNX model: {onnx_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Install onnx2tf if not already installed\n",
        "        !pip install onnx2tf\n",
        "        \n",
        "        print(\"\\nüîÑ Converting ONNX to TensorFlow SavedModel...\")\n",
        "        # Convert ONNX to TensorFlow SavedModel\n",
        "        !onnx2tf -i {onnx_path} -o {saved_model_path}\n",
        "        \n",
        "        if os.path.exists(saved_model_path):\n",
        "            print(f\"‚úÖ SavedModel created: {saved_model_path}\")\n",
        "            \n",
        "            print(\"\\nüîÑ Converting SavedModel to TensorFlow Lite...\")\n",
        "            # Convert to TensorFlow Lite\n",
        "            converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "            \n",
        "            # Enable quantization for smaller model size\n",
        "            converter.target_spec.supported_types = [tf.float16]\n",
        "            \n",
        "            tflite_model = converter.convert()\n",
        "            \n",
        "            # Save TFLite model\n",
        "            with open(tflite_path, 'wb') as f:\n",
        "                f.write(tflite_model)\n",
        "            \n",
        "            print(f\"‚úÖ TensorFlow Lite model saved: {tflite_path}\")\n",
        "            \n",
        "            # Get file sizes\n",
        "            onnx_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "            tflite_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "            \n",
        "            print(f\"\\nüìä Model Sizes:\")\n",
        "            print(f\"ONNX: {onnx_size:.2f} MB\")\n",
        "            print(f\"TFLite: {tflite_size:.2f} MB\")\n",
        "            print(f\"Compression ratio: {onnx_size/tflite_size:.2f}x\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå SavedModel conversion failed\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Conversion error: {str(e)}\")\n",
        "        print(\"\\nTrying alternative method with YOLOv5 export...\")\n",
        "        \n",
        "        # Alternative: Export directly from YOLOv5 to TensorFlow\n",
        "        os.chdir('yolov5')\n",
        "        weights_pattern = \"../Thesis/models/yolov5s_training*/weights/best.pt\"\n",
        "        weight_files = glob.glob(weights_pattern)\n",
        "        \n",
        "        if weight_files:\n",
        "            best_weights = weight_files[0]\n",
        "            !python export.py --weights {best_weights} --include saved_model tflite --img 640 --batch 1\n",
        "            \n",
        "            # Move generated files\n",
        "            source_tflite = best_weights.replace('best.pt', 'best-fp16.tflite')\n",
        "            if os.path.exists(source_tflite):\n",
        "                import shutil\n",
        "                shutil.copy2(source_tflite, f\"../{tflite_path}\")\n",
        "                print(f\"‚úÖ TensorFlow Lite model saved: {tflite_path}\")\n",
        "        \n",
        "        os.chdir('..')\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå ONNX model not found: {onnx_path}\")\n",
        "    print(\"Please run the ONNX export step first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Verify Exported Models and Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"           YOLOv5s TRAINING & EXPORT SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models_dir = Path(\"Thesis/models\")\n",
        "\n",
        "# Check for PyTorch weights\n",
        "pt_files = list(models_dir.glob(\"**/best.pt\"))\n",
        "if pt_files:\n",
        "    pt_path = pt_files[0]\n",
        "    pt_size = pt_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"‚úÖ PyTorch Model: {pt_path}\")\n",
        "    print(f\"   Size: {pt_size:.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ùå PyTorch model (.pt) not found\")\n",
        "\n",
        "# Check for ONNX model\n",
        "onnx_path = models_dir / \"yolov5s_best.onnx\"\n",
        "if onnx_path.exists():\n",
        "    onnx_size = onnx_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"‚úÖ ONNX Model: {onnx_path}\")\n",
        "    print(f\"   Size: {onnx_size:.2f} MB\")\n",
        "else:\n",
        "    # Check for ONNX in training directory\n",
        "    onnx_files = list(models_dir.glob(\"**/*.onnx\"))\n",
        "    if onnx_files:\n",
        "        onnx_path = onnx_files[0]\n",
        "        onnx_size = onnx_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"‚úÖ ONNX Model: {onnx_path}\")\n",
        "        print(f\"   Size: {onnx_size:.2f} MB\")\n",
        "    else:\n",
        "        print(\"‚ùå ONNX model (.onnx) not found\")\n",
        "\n",
        "# Check for TensorFlow Lite model\n",
        "tflite_path = models_dir / \"yolov5s_best.tflite\"\n",
        "if tflite_path.exists():\n",
        "    tflite_size = tflite_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"‚úÖ TensorFlow Lite Model: {tflite_path}\")\n",
        "    print(f\"   Size: {tflite_size:.2f} MB\")\n",
        "else:\n",
        "    # Check for TFLite in training directory\n",
        "    tflite_files = list(models_dir.glob(\"**/*.tflite\"))\n",
        "    if tflite_files:\n",
        "        tflite_path = tflite_files[0]\n",
        "        tflite_size = tflite_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"‚úÖ TensorFlow Lite Model: {tflite_path}\")\n",
        "        print(f\"   Size: {tflite_size:.2f} MB\")\n",
        "    else:\n",
        "        print(\"‚ùå TensorFlow Lite model (.tflite) not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"