{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f801ad",
   "metadata": {},
   "source": [
    "YOLOv5s Android Real-Time Detection Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3608f428",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dda9ba",
   "metadata": {},
   "source": [
    "INSTALL DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_dependencies():\n",
    "    print(\"Installing dependencies\")\n",
    "\n",
    "    packages = [\n",
    "        \"opencv-python\",\n",
    "        \"matplotlib\",\n",
    "        \"seaborn\",\n",
    "        \"pillow\",\n",
    "        \"pyyaml\",\n",
    "        \"tqdm\",\n",
    "        \"tensorboard\",\n",
    "        \"onnx\",\n",
    "        \"onnxruntime\",\n",
    "        \"tensorflow\",\n",
    "        \"tf2onnx\",\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"Failed to install {package}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d86fc",
   "metadata": {},
   "source": [
    "Clone YOLOv5 repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_yolov5_repo():\n",
    "    print(\"Cloning YOLOv5 repository\")\n",
    "    \n",
    "    if not os.path.exists(\"yolov5\"):\n",
    "        try:\n",
    "            subprocess.check_call([\"git\", \"clone\", \"https://github.com/ultralytics/yolov5.git\"])\n",
    "            print(\"YOLOv5 repository cloned successfully\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Failed to clone YOLOv5 repository\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"YOLOv5 repository already exists\")\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"yolov5/requirements.txt\"])\n",
    "        print(\"YOLOv5 requirements installed\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Failed to install YOLOv5 requirements\")\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61efa968",
   "metadata": {},
   "source": [
    "SETUP FOLDER STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure():\n",
    "    print(\"Creating folder structure\")\n",
    "    \n",
    "    folders = [\n",
    "        \"Thesis/dataset/images/train\",\n",
    "        \"Thesis/dataset/images/val\", \n",
    "        \"Thesis/dataset/labels/train\",\n",
    "        \"Thesis/dataset/labels/val\",\n",
    "        \"Thesis/input\",\n",
    "        \"Thesis/output\",\n",
    "        \"Thesis/metrics\",\n",
    "        \"Thesis/models\"\n",
    "    ]\n",
    "    \n",
    "    for folder in folders:\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created {folder}\")\n",
    "    \n",
    "    print(\"Folder structure created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f4b9f",
   "metadata": {},
   "source": [
    "Create data.yaml file for YOLOv5 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ae10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_yaml():\n",
    "    print(\"Creating dataset configuration\")\n",
    "\n",
    "    dataset_config = {\n",
    "        \"train\": \"Thesis/dataset/images/train\",\n",
    "        \"val\": \"Thesis/dataset/images/val\",\n",
    "        \"nc\": 2,\n",
    "        \"names\": [\"nsfw\", \"gore\"],\n",
    "    }\n",
    "\n",
    "    with open(\"Thesis/dataset/data.yaml\", \"w\") as f:\n",
    "        yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "    print(\"Dataset configuration file created\")\n",
    "    return \"Thesis/dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb9dc0",
   "metadata": {},
   "source": [
    "VALIDATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82524da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_structure():\n",
    "    print(\"Validating dataset structure\")\n",
    "\n",
    "    required_paths = [\n",
    "        \"Thesis/dataset/images/train\",\n",
    "        \"Thesis/dataset/images/val\",\n",
    "        \"Thesis/dataset/labels/train\",\n",
    "        \"Thesis/dataset/labels/val\",\n",
    "        \"Thesis/dataset/data.yaml\",\n",
    "    ]\n",
    "\n",
    "    for path in required_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Missing: {path}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"Found: {path}\")\n",
    "\n",
    "    train_images = len(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(\"Thesis/dataset/images/train\")\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\"))\n",
    "        ]\n",
    "    )\n",
    "    val_images = len(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(\"Thesis/dataset/images/val\")\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\"))\n",
    "        ]\n",
    "    )\n",
    "    train_labels = len(\n",
    "        [f for f in os.listdir(\"Thesis/dataset/labels/train\") if f.endswith(\".txt\")]\n",
    "    )\n",
    "    val_labels = len(\n",
    "        [f for f in os.listdir(\"Thesis/dataset/labels/val\") if f.endswith(\".txt\")]\n",
    "    )\n",
    "\n",
    "    print(f\"Training images: {train_images}, Training labels: {train_labels}\")\n",
    "    print(f\"Validation images: {val_images}, Validation labels: {val_labels}\")\n",
    "\n",
    "    if train_images == 0 or val_images == 0:\n",
    "        print(\"No images found in dataset folders\")\n",
    "        print(\"Will use preexisting YOLOv5 dataset for training\")\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805e9e9",
   "metadata": {},
   "source": [
    "Setup a preexisting YOLOv5 dataset when local dataset is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_preexisting_dataset():\n",
    "    print(\"Setting up preexisting YOLOv5 dataset\")\n",
    "\n",
    "    available_datasets = {\n",
    "        \"coco128\": {\n",
    "            \"url\": \"https://ultralytics.com/assets/coco128.zip\",\n",
    "            \"nc\": 80,\n",
    "            \"description\": \"COCO dataset subset (128 images, 80 classes)\",\n",
    "        },\n",
    "        \"voc\": {\n",
    "            \"yaml\": \"VOC.yaml\",\n",
    "            \"nc\": 20,\n",
    "            \"description\": \"Pascal VOC dataset (20 classes)\",\n",
    "        },\n",
    "        \"Objects365\": {\n",
    "            \"yaml\": \"Objects365.yaml\",\n",
    "            \"nc\": 365,\n",
    "            \"description\": \"Objects365 dataset (365 classes)\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    selected_dataset = \"coco128\"\n",
    "    print(\n",
    "        f\"Selected dataset: {selected_dataset} - {available_datasets[selected_dataset]['description']}\"\n",
    "    )\n",
    "\n",
    "    if selected_dataset == \"coco128\":\n",
    "        import zipfile\n",
    "        import urllib.request\n",
    "        from urllib.parse import urlparse\n",
    "\n",
    "        dataset_url = available_datasets[selected_dataset][\"url\"]\n",
    "        dataset_zip = \"coco128.zip\"\n",
    "\n",
    "        print(f\"Downloading {selected_dataset} dataset\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(dataset_url, dataset_zip)\n",
    "            print(f\"Downloaded {dataset_zip}\")\n",
    "\n",
    "            with zipfile.ZipFile(dataset_zip, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(\".\")\n",
    "            print(\"Extracted dataset\")\n",
    "\n",
    "            os.remove(dataset_zip)\n",
    "\n",
    "            coco128_config = {\n",
    "                \"train\": \"coco128/images/train2017\",\n",
    "                \"val\": \"coco128/images/train2017\",\n",
    "                \"nc\": 80,\n",
    "                \"names\": [\n",
    "                    \"person\",\n",
    "                    \"bicycle\",\n",
    "                    \"car\",\n",
    "                    \"motorcycle\",\n",
    "                    \"airplane\",\n",
    "                    \"bus\",\n",
    "                    \"train\",\n",
    "                    \"truck\",\n",
    "                    \"boat\",\n",
    "                    \"traffic light\",\n",
    "                    \"fire hydrant\",\n",
    "                    \"stop sign\",\n",
    "                    \"parking meter\",\n",
    "                    \"bench\",\n",
    "                    \"bird\",\n",
    "                    \"cat\",\n",
    "                    \"dog\",\n",
    "                    \"horse\",\n",
    "                    \"sheep\",\n",
    "                    \"cow\",\n",
    "                    \"elephant\",\n",
    "                    \"bear\",\n",
    "                    \"zebra\",\n",
    "                    \"giraffe\",\n",
    "                    \"backpack\",\n",
    "                    \"umbrella\",\n",
    "                    \"handbag\",\n",
    "                    \"tie\",\n",
    "                    \"suitcase\",\n",
    "                    \"frisbee\",\n",
    "                    \"skis\",\n",
    "                    \"snowboard\",\n",
    "                    \"sports ball\",\n",
    "                    \"kite\",\n",
    "                    \"baseball bat\",\n",
    "                    \"baseball glove\",\n",
    "                    \"skateboard\",\n",
    "                    \"surfboard\",\n",
    "                    \"tennis racket\",\n",
    "                    \"bottle\",\n",
    "                    \"wine glass\",\n",
    "                    \"cup\",\n",
    "                    \"fork\",\n",
    "                    \"knife\",\n",
    "                    \"spoon\",\n",
    "                    \"bowl\",\n",
    "                    \"banana\",\n",
    "                    \"apple\",\n",
    "                    \"sandwich\",\n",
    "                    \"orange\",\n",
    "                    \"broccoli\",\n",
    "                    \"carrot\",\n",
    "                    \"hot dog\",\n",
    "                    \"pizza\",\n",
    "                    \"donut\",\n",
    "                    \"cake\",\n",
    "                    \"chair\",\n",
    "                    \"couch\",\n",
    "                    \"potted plant\",\n",
    "                    \"bed\",\n",
    "                    \"dining table\",\n",
    "                    \"toilet\",\n",
    "                    \"tv\",\n",
    "                    \"laptop\",\n",
    "                    \"mouse\",\n",
    "                    \"remote\",\n",
    "                    \"keyboard\",\n",
    "                    \"cell phone\",\n",
    "                    \"microwave\",\n",
    "                    \"oven\",\n",
    "                    \"toaster\",\n",
    "                    \"sink\",\n",
    "                    \"refrigerator\",\n",
    "                    \"book\",\n",
    "                    \"clock\",\n",
    "                    \"vase\",\n",
    "                    \"scissors\",\n",
    "                    \"teddy bear\",\n",
    "                    \"hair drier\",\n",
    "                    \"toothbrush\",\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            with open(\"Thesis/dataset/data.yaml\", \"w\") as f:\n",
    "                yaml.dump(coco128_config, f, default_flow_style=False)\n",
    "\n",
    "            print(\"Created COCO128 dataset configuration\")\n",
    "            return \"Thesis/dataset/data.yaml\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download COCO128: {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        selected_config = available_datasets[selected_dataset]\n",
    "\n",
    "        builtin_config = {\n",
    "            \"train\": f'../{selected_config[\"yaml\"]}',\n",
    "            \"val\": f'../{selected_config[\"yaml\"]}',\n",
    "            \"nc\": selected_config[\"nc\"],\n",
    "            \"names\": [f\"class_{i}\" for i in range(selected_config[\"nc\"])],\n",
    "        }\n",
    "\n",
    "        with open(\"Thesis/dataset/data.yaml\", \"w\") as f:\n",
    "            yaml.dump(builtin_config, f, default_flow_style=False)\n",
    "\n",
    "        print(f\"Configured to use {selected_dataset} dataset\")\n",
    "        return \"Thesis/dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3336a",
   "metadata": {},
   "source": [
    "TRAINING CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05287a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv5Trainer:\n",
    "    def __init__(self, data_yaml_path, use_preexisting=False):\n",
    "        self.data_yaml_path = data_yaml_path\n",
    "        self.use_preexisting = use_preexisting\n",
    "        self.model_size = \"yolov5s\"\n",
    "        self.img_size = 640\n",
    "        self.batch_size = 16\n",
    "        self.epochs = 100 if not use_preexisting else 50\n",
    "        self.project = \"Thesis/training_results\"\n",
    "        self.name = \"yolov5s_training\"\n",
    "\n",
    "    def train_model(self):\n",
    "        if self.use_preexisting:\n",
    "            print(\"Starting YOLOv5s training with preexisting dataset\")\n",
    "        else:\n",
    "            print(\"Starting YOLOv5s training with custom dataset\")\n",
    "\n",
    "        os.chdir(\"yolov5\")\n",
    "\n",
    "        if self.use_preexisting and \"coco128\" in self.data_yaml_path:\n",
    "            data_path = \"../coco128.yaml\"\n",
    "            coco128_yaml = {\n",
    "                \"train\": \"coco128/images/train2017\",\n",
    "                \"val\": \"coco128/images/train2017\",\n",
    "                \"nc\": 80,\n",
    "                \"names\": [\n",
    "                    \"person\",\n",
    "                    \"bicycle\",\n",
    "                    \"car\",\n",
    "                    \"motorcycle\",\n",
    "                    \"airplane\",\n",
    "                    \"bus\",\n",
    "                    \"train\",\n",
    "                    \"truck\",\n",
    "                    \"boat\",\n",
    "                    \"traffic light\",\n",
    "                    \"fire hydrant\",\n",
    "                    \"stop sign\",\n",
    "                    \"parking meter\",\n",
    "                    \"bench\",\n",
    "                    \"bird\",\n",
    "                    \"cat\",\n",
    "                    \"dog\",\n",
    "                    \"horse\",\n",
    "                    \"sheep\",\n",
    "                    \"cow\",\n",
    "                    \"elephant\",\n",
    "                    \"bear\",\n",
    "                    \"zebra\",\n",
    "                    \"giraffe\",\n",
    "                    \"backpack\",\n",
    "                    \"umbrella\",\n",
    "                    \"handbag\",\n",
    "                    \"tie\",\n",
    "                    \"suitcase\",\n",
    "                    \"frisbee\",\n",
    "                    \"skis\",\n",
    "                    \"snowboard\",\n",
    "                    \"sports ball\",\n",
    "                    \"kite\",\n",
    "                    \"baseball bat\",\n",
    "                    \"baseball glove\",\n",
    "                    \"skateboard\",\n",
    "                    \"surfboard\",\n",
    "                    \"tennis racket\",\n",
    "                    \"bottle\",\n",
    "                    \"wine glass\",\n",
    "                    \"cup\",\n",
    "                    \"fork\",\n",
    "                    \"knife\",\n",
    "                    \"spoon\",\n",
    "                    \"bowl\",\n",
    "                    \"banana\",\n",
    "                    \"apple\",\n",
    "                    \"sandwich\",\n",
    "                    \"orange\",\n",
    "                    \"broccoli\",\n",
    "                    \"carrot\",\n",
    "                    \"hot dog\",\n",
    "                    \"pizza\",\n",
    "                    \"donut\",\n",
    "                    \"cake\",\n",
    "                    \"chair\",\n",
    "                    \"couch\",\n",
    "                    \"potted plant\",\n",
    "                    \"bed\",\n",
    "                    \"dining table\",\n",
    "                    \"toilet\",\n",
    "                    \"tv\",\n",
    "                    \"laptop\",\n",
    "                    \"mouse\",\n",
    "                    \"remote\",\n",
    "                    \"keyboard\",\n",
    "                    \"cell phone\",\n",
    "                    \"microwave\",\n",
    "                    \"oven\",\n",
    "                    \"toaster\",\n",
    "                    \"sink\",\n",
    "                    \"refrigerator\",\n",
    "                    \"book\",\n",
    "                    \"clock\",\n",
    "                    \"vase\",\n",
    "                    \"scissors\",\n",
    "                    \"teddy bear\",\n",
    "                    \"hair drier\",\n",
    "                    \"toothbrush\",\n",
    "                ],\n",
    "            }\n",
    "            with open(\"../coco128.yaml\", \"w\") as f:\n",
    "                yaml.dump(coco128_yaml, f, default_flow_style=False)\n",
    "        else:\n",
    "            data_path = f\"../{self.data_yaml_path}\"\n",
    "\n",
    "        train_cmd = [\n",
    "            sys.executable,\n",
    "            \"train.py\",\n",
    "            \"--data\",\n",
    "            data_path,\n",
    "            \"--weights\",\n",
    "            f\"{self.model_size}.pt\",\n",
    "            \"--img\",\n",
    "            str(self.img_size),\n",
    "            \"--batch-size\",\n",
    "            str(self.batch_size),\n",
    "            \"--epochs\",\n",
    "            str(self.epochs),\n",
    "            \"--project\",\n",
    "            f\"../{self.project}\",\n",
    "            \"--name\",\n",
    "            self.name,\n",
    "            \"--save-period\",\n",
    "            \"10\",\n",
    "            \"--cache\",\n",
    "        ]\n",
    "\n",
    "        if self.use_preexisting:\n",
    "            train_cmd.extend([\"--patience\", \"20\"])\n",
    "\n",
    "        try:\n",
    "            print(f\"Training command: {' '.join(train_cmd)}\")\n",
    "            result = subprocess.run(train_cmd, capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                print(\"Training completed successfully\")\n",
    "                print(\"Training output:\", result.stdout[-1000:])\n",
    "            else:\n",
    "                print(\"Training failed\")\n",
    "                print(\"Error:\", result.stderr)\n",
    "                return False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Training failed with exception: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            os.chdir(\"..\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_best_weights_path(self):\n",
    "        weights_path = f\"{self.project}/{self.name}/weights/best.pt\"\n",
    "        if os.path.exists(weights_path):\n",
    "            return weights_path\n",
    "        else:\n",
    "            print(f\"Best weights not found at {weights_path}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c323563",
   "metadata": {},
   "source": [
    "MODEL VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(weights_path, data_yaml_path):\n",
    "    print(\"Validating trained model\")\n",
    "\n",
    "    os.chdir(\"yolov5\")\n",
    "\n",
    "    val_cmd = [\n",
    "        sys.executable,\n",
    "        \"val.py\",\n",
    "        \"--data\",\n",
    "        f\"../{data_yaml_path}\",\n",
    "        \"--weights\",\n",
    "        f\"../{weights_path}\",\n",
    "        \"--img\",\n",
    "        \"640\",\n",
    "        \"--batch-size\",\n",
    "        \"16\",\n",
    "        \"--project\",\n",
    "        \"../Thesis/metrics\",\n",
    "        \"--name\",\n",
    "        \"validation_results\",\n",
    "        \"--save-txt\",\n",
    "        \"--save-conf\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(f\"Validation command: {' '.join(val_cmd)}\")\n",
    "        result = subprocess.run(val_cmd, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            print(\"Validation completed successfully\")\n",
    "            print(\"Validation output:\", result.stdout)\n",
    "        else:\n",
    "            print(\"Validation failed\")\n",
    "            print(\"Error:\", result.stderr)\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Validation failed with exception: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        os.chdir(\"..\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e587b5b",
   "metadata": {},
   "source": [
    "MODEL EXPORT FOR ANDROID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0659d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelExporter:\n",
    "    def __init__(self, weights_path):\n",
    "        self.weights_path = weights_path\n",
    "        self.models_dir = \"Thesis/models\"\n",
    "\n",
    "    def export_to_onnx(self):\n",
    "        print(\"Exporting model to ONNX\")\n",
    "\n",
    "        os.chdir(\"yolov5\")\n",
    "\n",
    "        onnx_cmd = [\n",
    "            sys.executable,\n",
    "            \"export.py\",\n",
    "            \"--weights\",\n",
    "            f\"../{self.weights_path}\",\n",
    "            \"--include\",\n",
    "            \"onnx\",\n",
    "            \"--img\",\n",
    "            \"640\",\n",
    "            \"--batch-size\",\n",
    "            \"1\",\n",
    "            \"--device\",\n",
    "            \"cpu\",\n",
    "            \"--simplify\",\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(onnx_cmd, capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                print(\"ONNX export completed successfully\")\n",
    "\n",
    "                onnx_dest = f\"{self.models_dir}/yolov5s_model.onnx\"\n",
    "\n",
    "                # Possible export locations\n",
    "                possible_paths = [\n",
    "                    self.weights_path.replace(\".pt\", \".onnx\"),\n",
    "                    os.path.join(\"yolov5\", \"best.onnx\"),\n",
    "                    os.path.join(\"yolov5\", f\"{os.path.basename(self.weights_path).replace('.pt','.onnx')}\"),\n",
    "                    \"yolov5s.onnx\"\n",
    "                ]\n",
    "\n",
    "                onnx_source = None\n",
    "                for path in possible_paths:\n",
    "                    if os.path.exists(path):\n",
    "                        onnx_source = path\n",
    "                        break\n",
    "\n",
    "                if onnx_source:\n",
    "                    shutil.move(onnx_source, onnx_dest)\n",
    "                    print(f\"ONNX model saved to {onnx_dest}\")\n",
    "                    return onnx_dest\n",
    "                else:\n",
    "                    print(\"ONNX file not found after export\")\n",
    "                    return None\n",
    "\n",
    "            else:\n",
    "                print(\"ONNX export failed\")\n",
    "                print(\"Error:\", result.stderr)\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ONNX export failed with exception: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            os.chdir(\"..\")\n",
    "\n",
    "    def export_to_tflite(self):\n",
    "        print(\"Exporting model to TensorFlow Lite\")\n",
    "\n",
    "        os.chdir(\"yolov5\")\n",
    "\n",
    "        tflite_cmd = [\n",
    "            sys.executable,\n",
    "            \"export.py\",\n",
    "            \"--weights\",\n",
    "            f\"../{self.weights_path}\",\n",
    "            \"--include\",\n",
    "            \"tflite\",\n",
    "            \"--img\",\n",
    "            \"640\",\n",
    "            \"--batch-size\",\n",
    "            \"1\",\n",
    "            \"--device\",\n",
    "            \"cpu\",\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(tflite_cmd, capture_output=True, text=True)\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                print(\"TensorFlow Lite export completed successfully\")\n",
    "\n",
    "                tflite_dest = f\"{self.models_dir}/yolov5s_model.tflite\"\n",
    "\n",
    "                possible_paths = [\n",
    "                    self.weights_path.replace(\".pt\", \".tflite\"),\n",
    "                    os.path.join(\"yolov5\", \"best.tflite\"),\n",
    "                    os.path.join(\"yolov5\", f\"{os.path.basename(self.weights_path).replace('.pt','.tflite')}\"),\n",
    "                    \"yolov5s.tflite\"\n",
    "                ]\n",
    "\n",
    "                tflite_source = None\n",
    "                for path in possible_paths:\n",
    "                    if os.path.exists(path):\n",
    "                        tflite_source = path\n",
    "                        break\n",
    "\n",
    "                if tflite_source:\n",
    "                    shutil.move(tflite_source, tflite_dest)\n",
    "                    print(f\"TensorFlow Lite model saved to {tflite_dest}\")\n",
    "                    return tflite_dest\n",
    "                else:\n",
    "                    print(\"TensorFlow Lite file not found after export\")\n",
    "                    return None\n",
    "\n",
    "            else:\n",
    "                print(\"TensorFlow Lite export failed\")\n",
    "                print(\"Error:\", result.stderr)\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"TensorFlow Lite export failed with exception: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb9613",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e206d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"YOLOv5s Android Real-Time Detection Training\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\nInstalling Dependencies\")\n",
    "        install_dependencies()\n",
    "\n",
    "        if not clone_yolov5_repo():\n",
    "            print(\"Failed to clone YOLOv5 repository. Exiting\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nSetting Up Folder Structure\")\n",
    "        create_folder_structure()\n",
    "        data_yaml_path = create_dataset_yaml()\n",
    "\n",
    "        print(\"\\nStep 3: Preparing Dataset\")\n",
    "\n",
    "        if not validate_dataset_structure():\n",
    "            print(\"No valid dataset found. Falling back to COCO128 demo dataset\")\n",
    "            data_yaml_path = setup_preexisting_dataset()\n",
    "            if not data_yaml_path:\n",
    "                print(\"Failed to set up fallback dataset. Exit\")\n",
    "                return\n",
    "\n",
    "        print(\"\\nTraining YOLOv5s Model\")\n",
    "        trainer = YOLOv5Trainer(data_yaml_path, use_preexisting=True)\n",
    "\n",
    "        if not trainer.train_model():\n",
    "            print(\"Training failed. Exit\")\n",
    "            return\n",
    "\n",
    "        best_weights = trainer.get_best_weights_path()\n",
    "        if not best_weights:\n",
    "            print(\"Could not find trained weights. Exit\")\n",
    "            return\n",
    "\n",
    "        print(f\"Best weights saved at: {best_weights}\")\n",
    "\n",
    "        print(\"\\nValidating Model\")\n",
    "        if not validate_model(best_weights, data_yaml_path):\n",
    "            print(\"Validation failed, but continuing with export\")\n",
    "\n",
    "        print(\"\\nExporting Model for Android\")\n",
    "        exporter = ModelExporter(best_weights)\n",
    "\n",
    "        onnx_path = exporter.export_to_onnx()\n",
    "        tflite_path = exporter.export_to_tflite()\n",
    "\n",
    "        print(\"TRAINING PIPELINE COMPLETED\")\n",
    "\n",
    "        print(\"\\nFinal Exported Files:\")\n",
    "        if onnx_path and os.path.exists(onnx_path):\n",
    "            print(f\"ONNX Model: {os.path.abspath(onnx_path)}\")\n",
    "        else:\n",
    "            print(\"ONNX export failed\")\n",
    "\n",
    "        if tflite_path and os.path.exists(tflite_path):\n",
    "            print(f\"TensorFlow Lite Model: {os.path.abspath(tflite_path)}\")\n",
    "        else:\n",
    "            print(\"TensorFlow Lite export failed\")\n",
    "\n",
    "        print(\n",
    "            f\"\\nTraining Results: {os.path.abspath(trainer.project)}/{trainer.name}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Validation Metrics: {os.path.abspath('Thesis/metrics/validation_results')}\"\n",
    "        )\n",
    "\n",
    "        print(\"\\nModels are ready for Android deployment\")\n",
    "\n",
    "        print(\"\\nComplete Project Structure:\")\n",
    "        for root, dirs, files in os.walk(\"Thesis\"):\n",
    "            level = root.replace(\"Thesis\", \"\").count(os.sep)\n",
    "            indent = \" \" * 2 * level\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            subindent = \" \" * 2 * (level + 1)\n",
    "            for file in files[:5]:\n",
    "                print(f\"{subindent}{file}\")\n",
    "            if len(files) > 5:\n",
    "                print(f\"{subindent}... and {len(files) - 5} more files\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nPipeline failed with error: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3994096",
   "metadata": {},
   "source": [
    "Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ead6d",
   "metadata": {},
   "source": [
    "Check if it meets requirements for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_system_requirements():\n",
    "    print(\"Checking system requirements\")\n",
    "\n",
    "    python_version = sys.version_info\n",
    "    print(\n",
    "        f\"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\"\n",
    "    )\n",
    "\n",
    "    if python_version.major != 3 or python_version.minor != 10:\n",
    "        print(\"Warning: Python 3.10 is recommended\")\n",
    "    \n",
    "    if shutil.which(\"git\") is None:\n",
    "        print(\"Git is not installed or not in PATH. Please install Git first.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA version: {torch.version.cuda}\")\n",
    "            print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not installed\")\n",
    "\n",
    "    import shutil\n",
    "\n",
    "    total, used, free = shutil.disk_usage(\".\")\n",
    "    print(f\"Available disk space: {free // (2**30)} GB\")\n",
    "\n",
    "    if free < 5 * (2**30):\n",
    "        print(\"Warning: Low disk space. Training requires at least 5GB free space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ac348",
   "metadata": {},
   "source": [
    "Create a training configuration file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_config():\n",
    "    config = {\n",
    "        \"model\": {\n",
    "            \"architecture\": \"yolov5s\",\n",
    "            \"input_size\": 640,\n",
    "            \"num_classes\": 2,\n",
    "            \"class_names\": [\"nsfw\", \"gore\"],\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"batch_size\": 16,\n",
    "            \"epochs\": 100,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"momentum\": 0.937,\n",
    "            \"weight_decay\": 0.0005,\n",
    "        },\n",
    "        \"export\": {\n",
    "            \"formats\": [\"onnx\", \"tflite\"],\n",
    "            \"optimize_for_mobile\": True,\n",
    "            \"quantization\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(\"Thesis/training_config.yaml\", \"w\") as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "    print(\"Training configuration saved to Thesis/training_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f746b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    check_system_requirements()\n",
    "    create_training_config()\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
